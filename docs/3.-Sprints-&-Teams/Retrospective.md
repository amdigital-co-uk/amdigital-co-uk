---
title: Sprint Retrospective
authors: Ed Earle
reviewed: 
reviewer:
next-review: 01-04-2022
---

| Guide | |
| ---: | :--- |
| **Objective:**        | Inspect team effectiveness and identify areas for improvement |
| **Organiser/Owner:**  | Delivery Team | 
| **Key stakeholders (required attendees):** | All delivery team members |
| **Scheduled:**        | Occurs the last day of the sprint |
| **Frequency:**        | 1 per sprint |
| **Team split:**       | 1 per delivery team, offset if possible |

# Overview
Each delivery team **should** inspect their working practices to understand ways in which they can be adapted to help improve overall effectiveness (i.e. quality, speed, sustainability). 


Scrum is founded upon empirical practices and outlines three pillars of empiricism: Transparency, Inspection, and Adaptation.
https://scrumguides.org/scrum-guide.html#scrum-theory 


The team **should** aim to 
1. _**use facts**_ (i.e. data) 
1. in order to _**draw insights**_ (i.e. ideas about causes) 
1. and then **[create experiments](#creating-and-managing-experiments)** (i.e. actions that may resolve/improve effectiveness in the specific area).

# Suggested Agenda
1. Review sprint effectiveness data. Ideally this will be the start.
1. Review existing experiments, identify experiments that are due for review, and ensure that ongoing experiments are being performed/measured well.
1. Explore new areas for improvement to produce new experiments. Use games and workshops to derive ideas and insights from all team members.

# Creating and Managing Experiments
## Creating
Experiments **must** be measurable, and the team **must** plan how and when measurements will be taken and reviewed, to understand if the experiment was successful.

Capture the experiments you are performing, for example in a Excel spreadsheet or Miro board. Capture:
- Reason - i.e. because of _[perceived problem (including supporting data)]_
- Insight - i.e. we believe this is because of _[cause]_
- Hypotheses - i.e. we believe this can be solved/improved if we do _[potential solution, plan of action]_
- Measures - i.e. we will monitor/record _[measurable outcomes]_ at _[expecific intervals/times]_ 
- Review point - i.e. we will review success _[date/after _n_ sprints]_
- Actions - i.e. things that must therefore be done by specific people/groups

**Note:**
- Be careful not to have too many experiments running at the same time. It may become hard to keep on top of them all
- Be careful that your experiments don't contradict, negatively impact, or skew the measurements of other experiments

## Reviewing
When you come to review the success of an experiment, you may decide to either:
1. Extend it, because it isn't clear what the result is yet
2. Stop it, because it was **successful**, and continue to perform this new behaviour
3. Stop it, because it was **unsuccessful**, and consider reviewing the insights drawn and then creating a new experiment
4. Pause it, because something is affecting your ability to perform the experiment well

**Remember to :**
- record the outcome, including new review dates etc.
- update documentation when you establish new behaviours.

# Tips for Success

- Consider what data you might need to inspect and work to ensure that that data is available to you. The enablement team can help to ensure this is done.
- Attend the Retrospectives of the other team(s) from time to time, to learn about other approaches and what experiments are being conducted elsewhere.
- Invite others (from the other team or the enablement team) to facilitate your retro occasionally. It can help to ensure all team members have an equal voice if an outsider plans and runs it.
- Mix it up now and then! Try different techniques, games, etc. as you explore your effectiveness and look for areas to improve.
- As with all meetings, make sure that virtual/remote participants voices are heard. As a remote participant you are equally responsible for being heard and participating actively.